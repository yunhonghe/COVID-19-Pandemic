{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunhonghe/COVID-19-Pandemic/blob/main/Sentiment_Analysis_Supervised_Machine_Learning_colab%20Aug%2016%202022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10a7d69a",
      "metadata": {
        "id": "10a7d69a"
      },
      "outputs": [],
      "source": [
        "# Mount My Google Drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a099e3b6",
      "metadata": {
        "id": "a099e3b6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import xgboost as xgb\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "RANDOM_SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read reviews label dataset\n",
        "train_review_df = pd.read_excel(f'c:\\\\Users\\\\heyun\\\\Capstone\\\\realtime_dreamer\\\\data\\\\processed\\\\train reviews.xlsx',engine='openpyxl',sheet_name='train', skiprows=0)\n",
        "print(train_review_df.shape)\n",
        "print(train_review_df['emotion'].value_counts())\n",
        "\n",
        "train_review_df.head()\n",
        "\n",
        "# Create dictionary for class labels\n",
        "label_dict = {'positive':2,'neutral': 1, 'negative':0}\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "def add_label_to_df(df):\n",
        "\n",
        "    \"\"\"Create function add_label_to_df to add label to reviews label dataset.\"\"\"  \n",
        "\n",
        "\n",
        "    df['label'] = df['emotion'].replace(label_dict)\n",
        "\n",
        "    return df\n",
        "\n",
        " \n",
        "\n",
        "def data_split(df):\n",
        "\n",
        "    \"\"\"\n",
        "    Create function data_split to \n",
        "    1. splict review lable dataset into train and validation data. \n",
        "    2. stratify the data to handle imbalance class issue.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    df=add_label_to_df(df)\n",
        "    X_train, X_val1, y_train, y_val1 = train_test_split(df.index.values,\n",
        "    df['label'].values,\n",
        "    test_size=0.20,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=df['label'].values)\n",
        "    \n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val1,\n",
        "                                                    y_val1,\n",
        "                                                    test_size=0.50,\n",
        "                                                    random_state=RANDOM_SEED,\n",
        "                                                    stratify=y_val1)\n",
        "  \n",
        "    return X_train, X_val, X_test,  y_train, y_val, y_test\n",
        "\n",
        "\n",
        "def set_data_category_in_df(df):\n",
        "  \n",
        "    \"\"\"Create function set_data_category_in_df to set data categary inside the reviews label data.\"\"\"\n",
        "\n",
        "\n",
        "    X_train, X_val, X_test,  y_train, y_val, y_test =data_split(df)    \n",
        "    df['data_category'] = ['unset']*df.shape[0]\n",
        "    df.loc[X_train, 'data_category'] = 'train'\n",
        "    df.loc[X_val, 'data_category'] = 'val'\n",
        "    df.loc[X_test, 'data_category'] = 'test'\n",
        "  \n",
        "    return df\n",
        "\n",
        "def vectorize_train_val_test_data(vec,df,col):\n",
        "\n",
        "    \"\"\"Create function vectorize_train_val_test_data to vectorize train and validation dataset\"\"\"\n",
        "    \n",
        "\n",
        "    X_train    = vec.fit_transform(df[df.data_category=='train'][col].values )\n",
        "    X_val  = vec.transform(df[df.data_category=='val'][col].values)\n",
        "    X_test = vec.transform(df[df.data_category=='test'][col].values)\n",
        "    \n",
        "    return X_train,X_val,X_test\n",
        "\n",
        "def calcualte_F1_scores(vec,clf,X_train,y_train,X_val,y_val):\n",
        "\n",
        "    \"\"\"Create function calcualte_F1_scores to calcuate 1_score_macro,f1_score_micro,f1_score_weighted.\"\"\"\n",
        "  \n",
        "  \n",
        "    if clf == gnb:\n",
        "        clf = clf.fit(X_train.toarray(), y_train)\n",
        "        predicted_y = clf.predict(X_val.toarray())\n",
        "    else:  \n",
        "        clf = clf.fit(X_train, y_train)    \n",
        "        predicted_y = clf.predict(X_val)\n",
        "        \n",
        "    f1_score_macro = f1_score(y_val,predicted_y, average='macro')\n",
        "    f1_score_micro = f1_score(y_val,predicted_y, average='micro')\n",
        "    f1_score_weighted = f1_score(y_val,predicted_y, average='weighted')\n",
        "\n",
        "    return f1_score_macro,f1_score_micro,f1_score_weighted\n",
        "\n",
        "def make_scores_dataset(vec):\n",
        "    \n",
        "    \"\"\"\n",
        "    Create function make_scores_dataset to \n",
        "    generate dataframe scores_df with F1_score_macro, F1_score_micro and F1_score_weighted.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    f1_macro_list=[]\n",
        "    f1_micro_list=[]\n",
        "    f1_weighted_list=[]\n",
        "\n",
        "    for clf in clf_list:\n",
        "        f1_macro,f1_micro,f1_weighted =calcualte_F1_scores(vec,clf,X_train,y_train,X_val,y_val)\n",
        "        f1_macro_list.append(f1_macro)\n",
        "        f1_micro_list.append(f1_micro)\n",
        "        f1_weighted_list.append(f1_weighted)\n",
        "\n",
        "    scores_df=pd.DataFrame()\n",
        "    scores_df['ML Classfier']=clf_name_list\n",
        "    scores_df['F1_score_macro']=f1_macro_list\n",
        "    scores_df['F1_score_micro']=f1_micro_list\n",
        "    scores_df['F1_score_weighted']=f1_weighted_list\n",
        "    scores_df.sort_values(by=['F1_score_macro','F1_score_micro','F1_score_weighted'],ascending=False, inplace=True)\n",
        "\n",
        "    return scores_df\n",
        "\n",
        "# Initiate TfidfVectorizer to convert a collection of review records to a matrix of TF-IDF features.\n",
        "vec = TfidfVectorizer(ngram_range=(1,3))\n",
        "\n",
        "# Splict review lable dataset into train and validation data\n",
        "_, _, _, y_train, y_val, y_test = data_split(train_review_df)\n",
        "\n",
        "# Set data categary inside the reviews label data\n",
        "emotion_df = set_data_category_in_df(train_review_df)\n",
        "\n",
        "# Vectorize train and validation dataset\n",
        "X_train, X_val, X_test = vectorize_train_val_test_data(vec, emotion_df, 'Review Content')\n",
        "\n",
        "# Initiate DummyClassifier, set strategy=\"uniform\"\n",
        "dummy_clf_uni = DummyClassifier(strategy=\"uniform\", random_state=RANDOM_SEED)\n",
        "\n",
        "# Initiate DummyClassifier, set strategy=\"most_frequent\"\n",
        "dummy_clf_mfrq = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_SEED)\n",
        "\n",
        "# Initiate LogisticRegression, set solver='lbfgs',multi_class='auto'\n",
        "lr_clf = LogisticRegression(random_state=RANDOM_SEED, solver='lbfgs',multi_class='auto',n_jobs=-1)\n",
        "\n",
        "# Initiate RandomForestClassifier\n",
        "rf_clf = RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1)\n",
        "\n",
        "# Initiate GaussianNB\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Initiate XGBClassifier\n",
        "xgb_clf        = xgb.sklearn.XGBClassifier()\n",
        "\n",
        "# Create clf_list for ML classifier\n",
        "clf_list = [dummy_clf_uni, dummy_clf_mfrq, lr_clf, rf_clf, gnb, xgb_clf]\n",
        "\n",
        "# Create clf_name_list for ML classifier names\n",
        "clf_name_list = ['dummy_clf_uniform', 'dummy_clf_most_frequent', 'LogisticRegression',\n",
        "                 'RandomForestClassifier', 'GaussianNB', 'XGBClassifier']\n",
        "\n",
        "# Create make_scores_df with F1_score_macro, F1_score_micro and F1_score_weighted\n",
        "make_scores_df = make_scores_dataset(vec)\n",
        "\n",
        "# Create sorted list sorted_clf with sorted name of ML classifers sorted by F1 score macro descending.\n",
        "sorted_clf = list(make_scores_df['ML Classfier'])\n",
        "\n",
        "# Create make_scores_df_long dataframe as long form of make_scores_df.\n",
        "make_scores_df_long = pd.melt(make_scores_df, \n",
        "                              id_vars=['ML Classfier'], \n",
        "                              value_vars=['F1_score_macro','F1_score_micro','F1_score_weighted'],\n",
        "                              var_name=['f1 score average type'])\n",
        "\n",
        "# Create graph for ML classifer model evaluation.\n",
        "graph = alt.Chart(make_scores_df_long).mark_bar(size=10).encode(\n",
        "        x = alt.X('ML Classfier:N', sort=sorted_clf, axis=alt.Axis(labelAngle=-90)),\n",
        "        y = alt.Y('value:Q', title='',scale=alt.Scale(domain=(0,1))),\n",
        "        color = alt.Color('f1 score average type:N',\n",
        "                          scale=alt.Scale(scheme='redyellowgreen'),\n",
        "                          legend=alt.Legend(orient='bottom',\n",
        "                                            titleFontSize=11,\n",
        "                                            titleColor='black',\n",
        "                                            labelFontSize=10.5,\n",
        "                                            labelColor='black',\n",
        "                                            direction='horizontal')),\n",
        "        column=alt.Column('f1 score average type:N',title='',sort=sorted_clf),\n",
        "        tooltip = ['ML Classfier',\n",
        "                   'f1 score average type',\n",
        "                   'value']\n",
        "        ).interactive(\n",
        "        ).properties(width=140,\n",
        "                     height=150\n",
        "                     )\n",
        "\n",
        "title = alt.Chart({\"values\": [{\"text\": \"Sentiment Analysis Supervised ML Model Evaluation\"}]}\n",
        "                      ).mark_text(size=15, dx=150, dy=0, color=\"black\"\n",
        "                      ).encode(text='text:N'\n",
        "                      ).properties(width=140,height=20)\n",
        "\n",
        "chart = (title & graph\n",
        "        ).configure_view(stroke=None\n",
        "        ).configure_concat(spacing=15\n",
        "        ).configure_title(fontSize=12)\n",
        "\n",
        "chart"
      ],
      "metadata": {
        "id": "Wv6zFkXY_JSw"
      },
      "id": "Wv6zFkXY_JSw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "991bf37e",
      "metadata": {
        "id": "991bf37e"
      },
      "outputs": [],
      "source": [
        "col_name = 'emotion'\n",
        "label_dict = {'positive':2,'neutral': 1, 'negative':0}\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "def add_label_to_df(df):\n",
        "\n",
        "    \"\"\"Add label to reviews label dataset.\"\"\"  \n",
        "\n",
        "\n",
        "    df['label'] = df['emotion'].replace(label_dict)\n",
        "\n",
        "    return df\n",
        "\n",
        " \n",
        "\n",
        "def data_split(df):\n",
        "\n",
        "    \"\"\"\n",
        "    Splict review lable dataset into train and validation data. \n",
        "    Stratify the data to handle imbalance class issue.\n",
        "    \"\"\"\n",
        "\n",
        "    df=add_label_to_df(df)\n",
        "    X_train, X_val1, y_train, y_val1 = train_test_split(df.index.values,\n",
        "    df['label'].values,\n",
        "    test_size=0.20,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=df[col_name].values)\n",
        "    \n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_val1,\n",
        "    y_val1,\n",
        "    test_size=0.50,\n",
        "    random_state=RANDOM_SEED,\n",
        "    stratify=y_val1)\n",
        "  \n",
        "    return X_train, X_val, X_test,  y_train, y_val, y_test\n",
        "\n",
        "\n",
        "def set_data_category_in_df(df):\n",
        "  \n",
        "    \"\"\"Set data categary inside the reviews label data.\"\"\"\n",
        "\n",
        "\n",
        "    X_train, X_val, X_test,  y_train, y_val, y_test =data_split(df)    \n",
        "    df['data_category'] = ['unset']*df.shape[0]\n",
        "    df.loc[X_train, 'data_category'] = 'train'\n",
        "    df.loc[X_val, 'data_category'] = 'val'\n",
        "    df.loc[X_test, 'data_category'] = 'test'\n",
        "  \n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3367afb",
      "metadata": {
        "id": "e3367afb"
      },
      "outputs": [],
      "source": [
        "def vectorize_train_val_test_data(vec,df,col):\n",
        "    \n",
        "    X_train    = vec.fit_transform(df[df.data_category=='train'][col].values )\n",
        "    X_val  = vec.transform(df[df.data_category=='val'][col].values)\n",
        "    X_test = vec.transform(df[df.data_category=='test'][col].values)\n",
        "    return X_train,X_val,X_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7add1132",
      "metadata": {
        "id": "7add1132"
      },
      "outputs": [],
      "source": [
        "def calcualte_F1_scores(vec,clf,X_train,y_train,X_val,y_val):\n",
        "\n",
        "  \n",
        "    if clf==gnb:\n",
        "        clf=clf.fit(X_train.toarray(), y_train)\n",
        "        predicted_y=clf.predict(X_val.toarray())\n",
        "    else:  \n",
        "        clf=clf.fit(X_train, y_train)    \n",
        "        predicted_y=clf.predict(X_val)\n",
        "        \n",
        "    f1_macro=f1_score(y_val,predicted_y, average='macro')\n",
        "    f1_micro=f1_score(y_val,predicted_y, average='micro')\n",
        "    f1_weighted=f1_score(y_val,predicted_y, average='weighted')\n",
        "\n",
        "    return f1_macro,f1_micro,f1_weighted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd25d41",
      "metadata": {
        "id": "edd25d41"
      },
      "outputs": [],
      "source": [
        "def make_scores_df(vec):\n",
        "    \n",
        "    f1_macro_list=[]\n",
        "    f1_micro_list=[]\n",
        "    f1_weighted_list=[]\n",
        "\n",
        "    for clf in clf_list:\n",
        "        f1_macro,f1_micro,f1_weighted =calcualte_F1_scores(vec,clf,X_train,y_train,X_val,y_val)\n",
        "        f1_macro_list.append(f1_macro)\n",
        "        f1_micro_list.append(f1_micro)\n",
        "        f1_weighted_list.append(f1_weighted)\n",
        "\n",
        "    scores_df=pd.DataFrame()\n",
        "    scores_df['clf']=clf_name_list\n",
        "    scores_df['f1_macro']=f1_macro_list\n",
        "    scores_df['f1_micro']=f1_micro_list\n",
        "    scores_df['f1_weighted']=f1_weighted_list\n",
        "    scores_df.sort_values(by=['f1_macro','f1_weighted','f1_micro'],ascending=False, inplace=True)\n",
        "    return scores_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b97859a8",
      "metadata": {
        "id": "b97859a8",
        "outputId": "a6976fcf-d69f-4fc2-aa94-feca23959a05"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clf</th>\n",
              "      <th>f1_macro</th>\n",
              "      <th>f1_micro</th>\n",
              "      <th>f1_weighted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>0.352466</td>\n",
              "      <td>0.831579</td>\n",
              "      <td>0.846779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dummy_clf_most_frequent</td>\n",
              "      <td>0.320267</td>\n",
              "      <td>0.924561</td>\n",
              "      <td>0.888321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.320267</td>\n",
              "      <td>0.924561</td>\n",
              "      <td>0.888321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.320267</td>\n",
              "      <td>0.924561</td>\n",
              "      <td>0.888321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.319951</td>\n",
              "      <td>0.922807</td>\n",
              "      <td>0.887444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dummy_clf_uniform</td>\n",
              "      <td>0.204032</td>\n",
              "      <td>0.321053</td>\n",
              "      <td>0.441688</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       clf  f1_macro  f1_micro  f1_weighted\n",
              "4               GaussianNB  0.352466  0.831579     0.846779\n",
              "1  dummy_clf_most_frequent  0.320267  0.924561     0.888321\n",
              "2       LogisticRegression  0.320267  0.924561     0.888321\n",
              "5            XGBClassifier  0.320267  0.924561     0.888321\n",
              "3   RandomForestClassifier  0.319951  0.922807     0.887444\n",
              "0        dummy_clf_uniform  0.204032  0.321053     0.441688"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
        "vec =bigram_vectorizer\n",
        "_, _, _,  y_train, y_val, y_test= data_split(train_review_df)\n",
        "emotion_df = set_data_category_in_df(train_review_df)\n",
        "X_train,X_val,X_test=vectorize_train_val_test_data(vec,emotion_df,'Review Content')\n",
        "dummy_clf_uni  = DummyClassifier(strategy=\"uniform\", random_state=RANDOM_SEED)\n",
        "dummy_clf_mfrq = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_SEED)\n",
        "lr_clf         = LogisticRegression(random_state=RANDOM_SEED, solver='lbfgs',multi_class='auto',n_jobs=-1)\n",
        "rf_clf         = RandomForestClassifier( random_state=RANDOM_SEED, n_jobs=-1)\n",
        "gnb            = GaussianNB()\n",
        "xgb_clf        = xgb.sklearn.XGBClassifier()\n",
        "clf_list =[dummy_clf_uni,dummy_clf_mfrq , lr_clf,rf_clf,gnb,xgb_clf]\n",
        "clf_name_list=['dummy_clf_uniform','dummy_clf_most_frequent','LogisticRegression',\n",
        "                   'RandomForestClassifier','GaussianNB','XGBClassifier']\n",
        "make_scores_df(vec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_scores_df = make_scores_df.sort_values(by=['f1_macro', 'f1_micro', 'f1_weighted'], ascending=False)\n",
        "sorted_clf = list(make_scores_df.clf)"
      ],
      "metadata": {
        "id": "2Kr45d-f7vmx"
      },
      "id": "2Kr45d-f7vmx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_scores_df_long = pd.melt(df_f1_scores, \n",
        "                              id_vars=['clf'], \n",
        "                              value_vars=['f1_macro', 'f1_micro', 'f1_weighted'],\n",
        "                              var_name=['f1 score average type'])"
      ],
      "metadata": {
        "id": "8hZNuJqb9qfg"
      },
      "id": "8hZNuJqb9qfg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a54ed189",
      "metadata": {
        "id": "a54ed189"
      },
      "outputs": [],
      "source": [
        "graph = alt.Chart(make_scores_df_long).mark_bar(size=10).encode(\n",
        "        x = alt.X('clf:N', sort=sorted_clf),\n",
        "        y = alt.Y('value:Q', title='',scale=alt.Scale(domain=(0,1))),\n",
        "        color = alt.Color('f1 score average type:N',\n",
        "                          scale=alt.Scale(scheme='redyellowgreen'),\n",
        "                          legend=alt.Legend(orient='bottom',\n",
        "                                            titleFontSize=11,\n",
        "                                            titleColor='black',\n",
        "                                            labelFontSize=10.5,\n",
        "                                            labelColor='black',\n",
        "                                            direction='horizontal')),\n",
        "        tooltip = ['clf',\n",
        "                   'f1 score average type',\n",
        "                   'value']\n",
        "        ).interactive(\n",
        "        ).properties(width=140,\n",
        "                     height=150,\n",
        "                     title=score_column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6b700d",
      "metadata": {
        "id": "cb6b700d"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "Sentiment Analysis Supervised Machine Learning-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}